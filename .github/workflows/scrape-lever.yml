name: Scrape Lever (Mon/Wed/Fri 6PM UTC)

on:
  schedule:
    # Weekday evening slot (jobs are posted Mon-Fri)
    - cron: '0 18 * * 1'  # Monday at 6:00 PM UTC
    - cron: '0 18 * * 3'  # Wednesday at 6:00 PM UTC
    - cron: '0 18 * * 5'  # Friday at 6:00 PM UTC
  workflow_dispatch:  # Manual trigger

jobs:
  lever:
    runs-on: ubuntu-latest
    timeout-minutes: 30  # 169 companies - allows 10min buffer over typical 20min runtime

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run Lever scraper
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          LLM_PROVIDER: gemini
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python wrappers/fetch_jobs.py --sources lever

      - name: Summary
        if: always()
        run: |
          echo "## Lever Scrape Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Companies:** 169" >> $GITHUB_STEP_SUMMARY
          echo "- **Source:** config/lever/company_mapping.json" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp:** $(date -u)" >> $GITHUB_STEP_SUMMARY
