# Repository Cleanup Plan - November 24, 2025

## Current Status Summary

**âœ… COMPLETED:**
- Epic 1: Data Ingestion Pipeline (Adzuna + Greenhouse dual-source)
- Epic 2: Job Classification & Enrichment (Claude 3.5 Haiku)
- Epic 3: Database & Data Layer (Supabase PostgreSQL)
- Adzuna Integration: Fixed and tested (3 bugs resolved)
- Greenhouse Integration: Operational (24 verified companies, 1,045 jobs)
- E2E Pipeline: Verified working end-to-end

**ğŸ”´ BLOCKED:**
- Epic 4: Pipeline Validation & Economics (needs `validate_pipeline.py` run)

**â³ PLANNED:**
- Epic 5: Analytics Query Layer
- Epic 6: Dashboard & Visualization
- Epic 7: Automation & Operational Excellence

---

## 1. Documentation Files to Update

### High Priority - Core Documentation

#### âœ… CLAUDE.md (Main development guide)
**Status:** Needs epic status update
**Updates needed:**
- Mark Epic 1-3 as COMPLETE
- Update Adzuna integration status (fixed, tested, working)
- Add note about Nov 24 fixes (dict-to-UnifiedJob conversion)
- Update Epic 4 as next priority

#### âœ… docs/system_architecture.yaml
**Status:** Needs pipeline status update
**Updates needed:**
- Update dual-pipeline status to "operational"
- Add Adzuna integration details
- Note agency filtering working (hard + soft)
- Update cost per job: $0.00168 (verified)

#### âœ… docs/product_brief.yaml
**Status:** Review for accuracy
**Updates needed:**
- Confirm Epic 1-3 completion
- Update timeline/roadmap if present

#### âš ï¸ FIXES_APPLIED_2025-11-24.md
**Status:** Move to docs/archive/
**Reason:** Completed fixes, keep for reference but archive

---

## 2. Test Files - Cleanup Strategy

### A. Root-Level Test Files (ARCHIVE)

**Move to `docs/archive/tests/`:**

```
test_classify_only.py            â†’ One-off classification test
test_dedupe_only.py              â†’ One-off dedup test
test_greenhouse_only.py          â†’ Superseded by test_greenhouse_scraper_simple.py
test_insert_greenhouse.py        â†’ One-off insertion test
test_store_only.py               â†’ One-off storage test
test_unified_job_fix.py          â†’ Verification test for Nov 24 fix (keep as reference)
test_pipeline_integration.py     â†’ Integration test (keep for reference)
test_database_insertion.py       â†’ DB test (keep for reference)
```

**KEEP (potentially useful for validation):**
```
test_full_pipeline_scale.py      â†’ Scale testing - useful for Epic 4 validation
```

### B. Active Test Suite (tests/ directory)

**KEEP - Active tests:**
```
tests/test_greenhouse_scraper_simple.py   â†’ Core scraper test
tests/test_two_companies.py               â†’ Multi-company test
tests/test_end_to_end.py                  â†’ E2E validation
tests/test_ats_scraping.py                â†’ ATS validation
tests/test_orchestrator.py                â†’ Pipeline orchestration test
tests/test_failed_job.py                  â†’ Error handling test
```

---

## 3. JSON/CSV Output Files - Cleanup

### A. Validation Outputs (CONSOLIDATE)

**Current files:**
```
validation_metrics.json
validation_metrics_debug.json
validation_metrics_fast.json
validation_metrics_adzuna_only.json
validation_metrics_full_pipeline.json
validation_test.json
validation_both_sources.json
```

**Action:** Move to `output/validation_history/` except:
- Keep: `validation_metrics_full_pipeline.json` (most comprehensive)
- Archive rest as historical

### B. Test Outputs (ARCHIVE)

**Move to `output/test_outputs/`:**
```
test_merged_jobs.json
test_classified_jobs.json
test_greenhouse_jobs.json
```

### C. Keep Active
```
greenhouse_validation_results.json       â†’ ATS validation results
greenhouse_validation_results.csv        â†’ Same, CSV format
config/company_ats_mapping.json          â†’ Active config
```

---

## 4. Documentation Archive Review

### Files in docs/archive/ (KEEP - Historical Reference)

**Already archived correctly:**
```
docs/archive/ATS_SCRAPING_GUIDE.md
docs/archive/FINDINGS_AND_RECOMMENDATION.md
docs/archive/INDEED_VS_ADZUNA_COMPARISON.md
docs/archive/ATS_ANALYSIS_STRATEGIC_REPORT.md
docs/archive/INDEPENDENT_SCRAPING_FEASIBILITY.md
docs/archive/HYBRID_SCRAPING_IMPLEMENTATION_COMPLETE.md
docs/archive/ATS_SCRAPING_TEST_RESULTS.md
docs/archive/GREENHOUSE_SCRAPER_STATUS.md
docs/archive/IMPLEMENTATION_COMPLETE.md
docs/archive/REPOSITORY_AUDIT_AND_RECOMMENDATIONS.md
docs/archive/CLEANUP_COMPLETE_SUMMARY.md
docs/archive/CLEANUP_QUICK_REFERENCE.md
```

**Action:** These are fine, no changes needed.

---

## 5. Active Documentation (KEEP & MAINTAIN)

```
docs/README.md                           â†’ Documentation index
docs/blacklisting_process.md             â†’ Agency detection methodology
docs/testing/GREENHOUSE_VALIDATION.md    â†’ Test documentation
docs/database/SCHEMA_UPDATES.md          â†’ Schema migration docs
docs/architecture/DUAL_PIPELINE.md       â†’ Architecture deep-dive
scrapers/greenhouse/README.md            â†’ Greenhouse scraper docs
```

---

## 6. Execution Plan

### Phase 1: Create Archive Directories
```bash
mkdir -p docs/archive/tests
mkdir -p output/validation_history
mkdir -p output/test_outputs
```

### Phase 2: Move Test Files
```bash
# Move root-level test files to archive
mv test_classify_only.py docs/archive/tests/
mv test_dedupe_only.py docs/archive/tests/
mv test_greenhouse_only.py docs/archive/tests/
mv test_insert_greenhouse.py docs/archive/tests/
mv test_store_only.py docs/archive/tests/
mv test_unified_job_fix.py docs/archive/tests/
mv test_pipeline_integration.py docs/archive/tests/
mv test_database_insertion.py docs/archive/tests/
```

### Phase 3: Move JSON Outputs
```bash
# Move validation outputs
mv validation_metrics.json output/validation_history/
mv validation_metrics_debug.json output/validation_history/
mv validation_metrics_fast.json output/validation_history/
mv validation_metrics_adzuna_only.json output/validation_history/
mv validation_test.json output/validation_history/
mv validation_both_sources.json output/validation_history/

# Move test outputs
mv test_merged_jobs.json output/test_outputs/
mv test_classified_jobs.json output/test_outputs/
mv test_greenhouse_jobs.json output/test_outputs/
```

### Phase 4: Move Recent Fixes Doc
```bash
mv FIXES_APPLIED_2025-11-24.md docs/archive/
```

### Phase 5: Update Core Documentation
1. Update CLAUDE.md (Epic status)
2. Update docs/system_architecture.yaml (pipeline status)
3. Update docs/product_brief.yaml (timeline)
4. Review docs/README.md (ensure accurate)

---

## 7. Final Repository Structure

```
job-analytics/
â”œâ”€â”€ CLAUDE.md                          â† Updated with current status
â”œâ”€â”€ fetch_jobs.py                      â† Main pipeline
â”œâ”€â”€ classifier.py                      â† LLM integration
â”œâ”€â”€ unified_job_ingester.py            â† Merge logic
â”œâ”€â”€ db_connection.py                   â† Database layer
â”œâ”€â”€ agency_detection.py                â† Agency filtering
â”œâ”€â”€ backfill_agency_flags.py           â† Maintenance
â”œâ”€â”€ validate_pipeline.py               â† Epic 4 (to run)
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agency_blacklist.yaml          â† Active config
â”‚   â”œâ”€â”€ supported_ats.yaml             â† Active config
â”‚   â””â”€â”€ company_ats_mapping.json       â† Active config
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md                      â† Updated index
â”‚   â”œâ”€â”€ system_architecture.yaml       â† Updated status
â”‚   â”œâ”€â”€ schema_taxonomy.yaml           â† Active spec
â”‚   â”œâ”€â”€ product_brief.yaml             â† Updated timeline
â”‚   â”œâ”€â”€ marketplace_questions.yaml     â† Active spec
â”‚   â”œâ”€â”€ blacklisting_process.md        â† Active doc
â”‚   â”œâ”€â”€ DATABASE_SCHEMA_UPDATE.md      â† Schema docs
â”‚   â”œâ”€â”€ architecture/
â”‚   â”‚   â””â”€â”€ DUAL_PIPELINE.md
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ SCHEMA_UPDATES.md
â”‚   â”œâ”€â”€ testing/
â”‚   â”‚   â””â”€â”€ GREENHOUSE_VALIDATION.md
â”‚   â””â”€â”€ archive/                       â† Historical docs + old tests
â”‚
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ adzuna/
â”‚   â”‚   â”œâ”€â”€ fetch_adzuna_jobs.py       â† Active
â”‚   â”‚   â””â”€â”€ sample_adzuna_jobs.csv
â”‚   â””â”€â”€ greenhouse/
â”‚       â”œâ”€â”€ greenhouse_scraper.py      â† Active
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ tests/                             â† Active test suite only
â”‚   â”œâ”€â”€ test_greenhouse_scraper_simple.py
â”‚   â”œâ”€â”€ test_two_companies.py
â”‚   â”œâ”€â”€ test_end_to_end.py
â”‚   â”œâ”€â”€ test_ats_scraping.py
â”‚   â”œâ”€â”€ test_orchestrator.py
â”‚   â””â”€â”€ test_failed_job.py
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ validation_history/            â† Old validation runs
â”‚   â”œâ”€â”€ test_outputs/                  â† Old test outputs
â”‚   â””â”€â”€ [other generated files]
â”‚
â””â”€â”€ [Keep]
    â”œâ”€â”€ test_full_pipeline_scale.py    â† Useful for Epic 4
    â”œâ”€â”€ greenhouse_validation_results.json
    â”œâ”€â”€ greenhouse_validation_results.csv
    â””â”€â”€ validation_metrics_full_pipeline.json
```

---

## 8. Success Criteria

**After cleanup:**
- âœ… Root directory has only active scripts + main docs
- âœ… All one-off test files archived
- âœ… Historical JSON outputs moved to output/
- âœ… Core documentation updated with current status
- âœ… Clear separation: active code vs. archived artifacts
- âœ… Easy to understand what's in production vs. testing

---

## 9. Next Steps After Cleanup

1. **Run Epic 4 validation:** `python validate_pipeline.py --cities lon,nyc --max-jobs 100`
2. **Review validation results:** Confirm unit economics and quality
3. **Proceed to Epic 5:** Build analytics.py query layer
4. **Streamlit dashboard:** Epic 6 implementation
